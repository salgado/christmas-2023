{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mg3hELMHfZ0"
      },
      "source": [
        "This code refers to the blog:\n",
        "\n",
        "Title: [EN] Santa Claus Meets Generative AI: Deciphering Handwritten Christmas Letters with LLM, LangChain, and Elasticsearch\n",
        "\n",
        "Author: Alex Salgado\n",
        "\n",
        "Link: https://discuss.elastic.co/t/dec-22nd-2023-en-santa-claus-meets-genai-deciphering-handwritten-christmas-letters-with-llm-langchain-and-elasticsearch/347311"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwFTg6N9JVR6"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/salgado/christmas-2023/blob/main/04_advent_calendar_en.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPN7Ug7JSzFV"
      },
      "source": [
        "\n",
        "# Santa Claus Meets Generative AI: Deciphering Handwritten Christmas Letters with LLM, LangChain and Elasticsearch\n",
        "\n",
        "In the heart of the North Pole, Santa Claus' team of elves faced a formidable logistical challenge: how to handle millions of letters from children around the world. With a determined look, Santa Claus decided that it was time to incorporate artificial intelligence into the Christmas operation.\n",
        "\n",
        "Sitting at his computer, equipped with the latest in AI technology, Santa Claus began to work on a Python script in Jupyter Notebook. The goal was simple, but ambitious: to use Large Language Models (LLM) and LangChain to interpret handwritten letters and extract the necessary data, inserting it in an organized manner into Elasticsearch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlFkqNkWIj-f",
        "outputId": "af000497-666f-42fa-e234-e5a04cb5d29b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: elasticsearch in /usr/local/lib/python3.10/dist-packages (8.11.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.351)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.5.0)\n",
            "Requirement already satisfied: elastic-transport<9,>=8 in /usr/local/lib/python3.10/dist-packages (from elasticsearch) (8.11.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.4)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.1)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.70 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.72)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.25.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8->elasticsearch) (2.0.7)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8->elasticsearch) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install python-dotenv elasticsearch langchain openai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66piJpfaTyDf"
      },
      "source": [
        "The first step was to set up the environment variables that would be used as credentials for accessing the OpenAI and Elasticsearch APIs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEE71fflIkfr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Replace 'path/to/your/.env' with the correct path to your .env file on Google Drive.\n",
        "env_path = '/content/drive/MyDrive/@Blogs/04-Advent-2023/env_advent'\n",
        "load_dotenv(env_path)\n",
        "\n",
        "# OpenAI API Key\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
        "OPENAI_API_URL = \"https://api.openai.com/v1/chat/completions\"\n",
        "\n",
        "# Elastic cloud credentials\n",
        "es_cloud_id = os.getenv('cloud_id')\n",
        "es_user = os.getenv('cloud_user')\n",
        "es_pass = os.getenv('cloud_pass')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "rvAZWQL5kzbx"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eylgvbjUfxL"
      },
      "source": [
        "Next, with a scanned image of a Christmas letter, Santa Claus wrote a script to extract the text using \"gpt-4-vision-preview\". This crucial step transformed the handwritten writing into digital text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tit6YhYOpSk3",
        "outputId": "4a6106b2-1d64-432c-ea31-06260229bb20"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema.messages import HumanMessage, SystemMessage\n",
        "\n",
        "image_path = 'https://i.imgur.com/IxC9lgd.png'\n",
        "\n",
        "chat = ChatOpenAI(model=\"gpt-4-vision-preview\", max_tokens=512)\n",
        "result = chat.invoke(\n",
        "    [\n",
        "        HumanMessage(\n",
        "            content=[\n",
        "                {\"type\": \"text\", \"text\": \"What is in the picture? Please provide a detailed introduction.\"},\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": image_path,\n",
        "                        \"detail\": \"auto\",\n",
        "                    },\n",
        "                },\n",
        "            ]\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "print(result.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNTL9AENZeYp"
      },
      "source": [
        "Next, LangChain came into action, analyzing the text and identifying key elements such as the child's name and the wish list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "GfsDlm3PdNWh"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import StrOutputParser\n",
        "\n",
        "chain = ChatOpenAI(model=\"gpt-3.5-turbo\", max_tokens=1024)\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "\"\"\"\n",
        "Extract the list and child's name from the text below and return the data in JSON format using the following name:\n",
        "- \"child_name\", \"wishlist\".\n",
        "\n",
        "{santalist}\n",
        "\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "runnable = prompt | chain | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tsdiubXuN92",
        "outputId": "15b8a9a3-70ae-4ee1-b1ff-3c99ba6ce668"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"child_name\": \"Maria\",\n",
            "  \"wishlist\": [\n",
            "    \"Barbie Dreamhouse Adventures\",\n",
            "    \"My Little Pony\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "letter = result.content\n",
        "wishlist = runnable.invoke({\"santalist\": letter})\n",
        "print(wishlist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn-AFw3Pd-fO"
      },
      "source": [
        "Santa Claus decided to enrich the database a bit, and also asked the AI to estimate the weight of these gifts. This way, he can generate a list in Kibana with the children's gifts divided into each bag and that fit within the space of a sleigh, what organization!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "L1N59ZsaG8rL"
      },
      "outputs": [],
      "source": [
        "chain = ChatOpenAI(model=\"gpt-3.5-turbo\", max_tokens=1024)\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "\"\"\"\n",
        "\n",
        "{santalist_json}\n",
        "\n",
        "From the JSON above, include a new attribute in the JSON called 'weight',\n",
        "which will calculate the total estimated weight of each item in the list in kilograms.\n",
        "You will first need to estimate the weight of each item individually.\n",
        "After that, sum these values to obtain the total weight.\n",
        "Extract only the numerical value.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "runnable = prompt | chain | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ous2GooY5arD",
        "outputId": "efbdb8ce-3b6e-4de8-bee0-f8b994da0a91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"child_name\": \"Maria\",\n",
            "  \"wishlist\": [\n",
            "    \"Barbie Dreamhouse Adventures\",\n",
            "    \"My Little Pony\"\n",
            "  ],\n",
            "  \"weight\": 0.5\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "new_wishlist = runnable.invoke({\"santalist_json\": wishlist})\n",
        "print(new_wishlist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "jTwCFuulOvLS"
      },
      "outputs": [],
      "source": [
        "# Insert into Elasticsearch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a32Is3FWegYo"
      },
      "source": [
        "Now, with the data structured, it was time to move them into Elasticsearch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ecB8BWjuOyVD"
      },
      "outputs": [],
      "source": [
        "from elasticsearch import Elasticsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gk4Ek6m8DPwn",
        "outputId": "bb89f09f-ebad-4a53-fd78-ad20f4a02a72"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ObjectApiResponse({'name': 'instance-0000000001', 'cluster_name': 'c731f6bbb8314543bb3648440b501e47', 'cluster_uuid': 'pdZVQFRuTr2u3yh4l0sZyg', 'version': {'number': '8.11.2', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '76013fa76dcbf144c886990c6290715f5dc2ae20', 'build_date': '2023-12-05T10:03:47.729926671Z', 'build_snapshot': False, 'lucene_version': '9.8.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "es = Elasticsearch(cloud_id=es_cloud_id,\n",
        "                  basic_auth=(es_user, es_pass)\n",
        "                  )\n",
        "es.info() # should return cluster info\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "cjwAWuq8IGj5"
      },
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPiE0ey2GTTa",
        "outputId": "bc489953-2268-4fe6-8344-57958ef20eba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'_index': 'santa_claus_list', '_id': 'nV8XhIwBrZtDJJrwaZX4', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 2, 'failed': 0}, '_seq_no': 9, '_primary_term': 1}\n"
          ]
        }
      ],
      "source": [
        "# Parse the JSON string\n",
        "json_string = new_wishlist\n",
        "data = json.loads(json_string)\n",
        "\n",
        "# Index name\n",
        "index_name = \"santa_claus_list\"\n",
        "\n",
        "# Index the document\n",
        "response = es.index(index=index_name, document=data)\n",
        "\n",
        "# Print the response from Elasticsearch\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCa-5L0FiqJ-"
      },
      "source": [
        "Usando o Kibana, uma interface de visualização do Elasticsearch, Papai Noel e os duendes poderiam então facilmente buscar e analisar os dados. Isso permitia uma visão clara das tendências de presentes deste ano, as localizações mais frequentes das cartas, e até mesmo identificar aquelas cartas que expressavam desejos particulares ou urgentes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKMsyYD5irvi"
      },
      "outputs": [],
      "source": [
        " # As in this query using Elasticsearch SQL (ES|QL):\n",
        "\n",
        "POST /_query?format=txt\n",
        "{\n",
        "  \"query\": \"\"\"\n",
        "FROM santa_claus_list\n",
        "| STATS  sum_toy = SUM(weight) BY child_name\n",
        "| LIMIT 100\n",
        "  \"\"\"\n",
        "}\n",
        "\n",
        "# result\n",
        "    sum_toy    |  child_name\n",
        "---------------+---------------\n",
        "30.5           |Maria\n",
        "1.5            |Mike\n",
        "3.0            |Theo\n",
        "2.5            |Isabella\n",
        "40.0           |William\n",
        "30.0           |Olivia\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxEYW1s8izt0"
      },
      "source": [
        "Thanks to this innovative solution, Santa Claus was not only able to fulfill requests more efficiently but also gained valuable insights into the joys and hopes of children around the world, all thanks to the power of AI, LangChain, and Elasticsearch. This Christmas promised to be the most magical and well-organized ever!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
