{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mg3hELMHfZ0"
      },
      "source": [
        "Este código é referente ao blog:\n",
        "\n",
        "Título: [PT] Papai Noel Encontra a IA Generativa: Decifrando Cartas de Natal Escritas à Mão com LLM, LangChain e Elasticsearch\n",
        "\n",
        "Author: Alex Salgado\n",
        "\n",
        "Link: https://discuss.elastic.co/t/dec-22nd-2023-en-santa-claus-meets-genai-deciphering-handwritten-christmas-letters-with-llm-langchain-and-elasticsearch/347311\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwFTg6N9JVR6"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/salgado/christmas-2023/blob/main/04_advent_calendar_pt.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPN7Ug7JSzFV"
      },
      "source": [
        "\n",
        "# Santa Claus Meets AI: Deciphering Handwritten Christmas Letters with LLM, LangChain and Elasticsearch\n",
        "\n",
        "No coração do Polo Norte, a equipe de duendes de Papai Noel enfrentava um desafio logístico formidável: como lidar com milhões de cartas de crianças de todo o mundo. Com um olhar determinado, Papai Noel decidiu que era hora de incorporar inteligência artificial na operação natalina.\n",
        "\n",
        "Sentando-se em seu computador, equipado com o mais recente em tecnologia de IA, Papai Noel começou a trabalhar em um script Python no Jupyter Notebook. O objetivo era simples, mas ambicioso: utilizar Large Language Models (LLM) e LangChain para interpretar cartas manuscritas e extrair os dados necessários, inserindo-os de forma organizada no Elasticsearch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlFkqNkWIj-f",
        "outputId": "af000497-666f-42fa-e234-e5a04cb5d29b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: elasticsearch in /usr/local/lib/python3.10/dist-packages (8.11.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.351)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.5.0)\n",
            "Requirement already satisfied: elastic-transport<9,>=8 in /usr/local/lib/python3.10/dist-packages (from elasticsearch) (8.11.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.4)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.1)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.70 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.72)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.25.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8->elasticsearch) (2.0.7)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8->elasticsearch) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install python-dotenv elasticsearch langchain openai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66piJpfaTyDf"
      },
      "source": [
        "O primeiro passo foi configurar as variaveis de ambiente as quais seriam utilizadas como credenciais para acesso a api do openAi e do Elasticsearch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "FEE71fflIkfr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Substitua 'path/to/your/.env' pelo caminho correto até o seu arquivo .env no Google Drive\n",
        "env_path = '/content/drive/MyDrive/@Blogs/04-Advent-2023/env_advent'\n",
        "load_dotenv(env_path)\n",
        "\n",
        "# OpenAI API Key\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
        "OPENAI_API_URL = \"https://api.openai.com/v1/chat/completions\"\n",
        "\n",
        "# Elastic cloud credentials\n",
        "es_cloud_id = os.getenv('cloud_id')\n",
        "es_user = os.getenv('cloud_user')\n",
        "es_pass = os.getenv('cloud_pass')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "rvAZWQL5kzbx"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eylgvbjUfxL"
      },
      "source": [
        "A seguir, com uma imagem digitalizada de uma carta de Natal, Papai Noel escreveu um script para extrair o texto usando o \"gpt-4-vision-preview\". Essa etapa crucial transformou a escrita manual em texto digital."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tit6YhYOpSk3",
        "outputId": "4a6106b2-1d64-432c-ea31-06260229bb20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A imagem apresenta uma carta escrita à mão, que parece ser uma carta de uma criança para o Papai Noel. O texto está em português e é possível ler o seguinte:\n",
            "\n",
            "```\n",
            "Querido Papai Noel,\n",
            "\n",
            "Como vai você?\n",
            "\n",
            "Meu nome é Maria, tenho 8 anos e moro no Rio de Janeiro. Estou escrevendo esta carta para pedir-lhe um presente de Natal.\n",
            "\n",
            "Fui uma boa menina este ano. Fiz minha lição de casa, ajudei minha mãe e meu pai nos afazeres domésticos e fui gentil com meus amigos.\n",
            "\n",
            "Para o Natal deste ano, tenho alguns desejos. Aqui está minha lista:\n",
            "\n",
            "- Barbie Dreamhouse Adventures.\n",
            "- My Little Pony.\n",
            "\n",
            "Sei que você está muito ocupado, mas espero que possa trazer meu presente para mim.\n",
            "\n",
            "Obrigada, Papai Noel\n",
            "\n",
            "Com amor,\n",
            "\n",
            "Maria\n",
            "```\n",
            "\n",
            "A carta é um exemplo típico de uma mensagem que as crianças costumam enviar ao Papai Noel antes do Natal, expressando bons comportamentos e pedindo presentes. A caligrafia parece infantil, o que é coerente com a idade da autora mencionada, Maria, que diz ter 8 anos. Os presentes que ela pede são brinquedos populares entre crianças, especificamente \"Barbie Dreamhouse Adventures\" e \"My Little Pony\". A carta transmite uma sensação de inocência e esperança, características comuns nas cartas ao Papai Noel escritas por crianças.\n"
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema.messages import HumanMessage, SystemMessage\n",
        "\n",
        "image_path = 'https://i.imgur.com/JNK7hww.png'\n",
        "\n",
        "chat = ChatOpenAI(model=\"gpt-4-vision-preview\", max_tokens=512)\n",
        "result = chat.invoke(\n",
        "    [\n",
        "        HumanMessage(\n",
        "            content=[\n",
        "                {\"type\": \"text\", \"text\": \"Qual é a imagem? Por favor, forneça uma introdução detalhada em portugues.\"},\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": image_path,\n",
        "                        \"detail\": \"auto\",\n",
        "                    },\n",
        "                },\n",
        "            ]\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "print(result.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNTL9AENZeYp"
      },
      "source": [
        "Em seguida, o LangChain entrou em ação, analisando o texto e identificando elementos-chave como o nome da criança e a lista de desejos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "GfsDlm3PdNWh"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import StrOutputParser\n",
        "\n",
        "chain = ChatOpenAI(model=\"gpt-3.5-turbo\", max_tokens=1024)\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "\"\"\"\n",
        "Extract the list and child's name from the text below and return the data in JSON format using the following name:\n",
        "- \"child_name\", \"wishlist\".\n",
        "\n",
        "{santalist}\n",
        "\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "runnable = prompt | chain | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tsdiubXuN92",
        "outputId": "15b8a9a3-70ae-4ee1-b1ff-3c99ba6ce668"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"child_name\": \"Maria\",\n",
            "  \"wishlist\": [\n",
            "    \"Barbie Dreamhouse Adventures\",\n",
            "    \"My Little Pony\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "letter = result.content\n",
        "wishlist = runnable.invoke({\"santalist\": letter})\n",
        "print(wishlist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn-AFw3Pd-fO"
      },
      "source": [
        "O Papai Noel decidiu enriquecer um pouco a base de dados, e pediu ainda, que a IA estime o peso desses presentes. Assim ele pode gerar uma lista no Kibana com os presentes das crianças divididadas em cada sacola e que couberem dentro do espaço de um trenó, que organização!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "L1N59ZsaG8rL"
      },
      "outputs": [],
      "source": [
        "chain = ChatOpenAI(model=\"gpt-3.5-turbo\", max_tokens=1024)\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "\"\"\"\n",
        "\n",
        "{santalist_json}\n",
        "\n",
        "From the JSON above, include a new attribute in the JSON called 'weight',\n",
        "which will calculate the total estimated weight of each item in the list in kilograms.\n",
        "You will first need to estimate the weight of each item individually.\n",
        "After that, sum these values to obtain the total weight.\n",
        "Extract only the numerical value.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "runnable = prompt | chain | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ous2GooY5arD",
        "outputId": "efbdb8ce-3b6e-4de8-bee0-f8b994da0a91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"child_name\": \"Maria\",\n",
            "  \"wishlist\": [\n",
            "    \"Barbie Dreamhouse Adventures\",\n",
            "    \"My Little Pony\"\n",
            "  ],\n",
            "  \"weight\": 0.5\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "new_wishlist = runnable.invoke({\"santalist_json\": wishlist})\n",
        "print(new_wishlist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "jTwCFuulOvLS"
      },
      "outputs": [],
      "source": [
        "# Insert into Elasticsearch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a32Is3FWegYo"
      },
      "source": [
        "Agora, com os dados estruturados, era hora de movê-los para o Elasticsearch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ecB8BWjuOyVD"
      },
      "outputs": [],
      "source": [
        "from elasticsearch import Elasticsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gk4Ek6m8DPwn",
        "outputId": "bb89f09f-ebad-4a53-fd78-ad20f4a02a72"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ObjectApiResponse({'name': 'instance-0000000001', 'cluster_name': 'c731f6bbb8314543bb3648440b501e47', 'cluster_uuid': 'pdZVQFRuTr2u3yh4l0sZyg', 'version': {'number': '8.11.2', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': '76013fa76dcbf144c886990c6290715f5dc2ae20', 'build_date': '2023-12-05T10:03:47.729926671Z', 'build_snapshot': False, 'lucene_version': '9.8.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'})"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "es = Elasticsearch(cloud_id=es_cloud_id,\n",
        "                  basic_auth=(es_user, es_pass)\n",
        "                  )\n",
        "es.info() # should return cluster info\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "cjwAWuq8IGj5"
      },
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPiE0ey2GTTa",
        "outputId": "bc489953-2268-4fe6-8344-57958ef20eba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'_index': 'santa_claus_list', '_id': 'nV8XhIwBrZtDJJrwaZX4', '_version': 1, 'result': 'created', '_shards': {'total': 2, 'successful': 2, 'failed': 0}, '_seq_no': 9, '_primary_term': 1}\n"
          ]
        }
      ],
      "source": [
        "# Parse the JSON string\n",
        "json_string = new_wishlist\n",
        "data = json.loads(json_string)\n",
        "\n",
        "# Index name\n",
        "index_name = \"santa_claus_list\"\n",
        "\n",
        "# Index the document\n",
        "response = es.index(index=index_name, document=data)\n",
        "\n",
        "# Print the response from Elasticsearch\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCa-5L0FiqJ-"
      },
      "source": [
        "Usando o Kibana, uma interface de visualização do Elasticsearch, Papai Noel e os duendes poderiam então facilmente buscar e analisar os dados. Isso permitia uma visão clara das tendências de presentes deste ano, as localizações mais frequentes das cartas, e até mesmo identificar aquelas cartas que expressavam desejos particulares ou urgentes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKMsyYD5irvi"
      },
      "outputs": [],
      "source": [
        " # Como nessa query usando ES|QL\n",
        "\n",
        "POST /_query?format=txt\n",
        "{\n",
        "  \"query\": \"\"\"\n",
        "FROM santa_claus_list\n",
        "| STATS  sum_toy = SUM(weight) BY child_name\n",
        "| LIMIT 100\n",
        "  \"\"\"\n",
        "}\n",
        "\n",
        "# result\n",
        "    sum_toy    |  child_name\n",
        "---------------+---------------\n",
        "30.5           |Maria\n",
        "1.5            |Mike\n",
        "3.0            |Theo\n",
        "2.5            |Isabella\n",
        "40.0           |William\n",
        "30.0           |Olivia\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxEYW1s8izt0"
      },
      "source": [
        "Graças a esta solução inovadora, Papai Noel não só conseguiu atender aos pedidos de forma mais eficiente, mas também ganhou insights valiosos sobre as alegrias e esperanças das crianças ao redor do mundo, tudo graças ao poder da IA, LangChain, e Elasticsearch. Este Natal prometia ser o mais mágico e bem organizado de todos!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
